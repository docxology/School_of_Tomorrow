---
title: Film Theory
id: 6115001984374842925
author: Kirby Urner
published: 2015-08-18T20:19:00.005-07:00
updated: 2015-08-22T14:10:37.228-07:00
blog: bizmo_diaries
tags: 
---

I'm going out on a limb here to suggest a hallmark of fictional films is they participate in the same voyeurism as fictive theater in denying there's either an audience or a point of view.  We're complicit in this mutual agreement to suspend disbelief. 

To call it "voyeurism" maybe makes such outright denial sound bad or dark, however the motive is innocent enough and has to do with removing any troubling metaphysical questioning from the viewer's mind, such as "how could I, in the 21st Century, be witness to a battlefield in a war fought over a hundred, or even a thousand, years ago?" 

The obvious answer, "this isn't real" just gets in the way of getting into the fantasy.  The whole point of a cave-like theater, bright screen, surrounding sound, is to "put you right there" meaning the thoughts we don't want to be pestered with are such as "I'm staring at a screen in a dark room at events that never happened."  We can think that later, after getting our money's worth.

So just don't worry that movie cameras of this quality had not been invented yet and that those awesome sweeping aerial shots would have required technology unavailable at the time, not to mention awkward to deploy in the midst of battle. Forget the fact you were not alive at the time and could not have been a direct witness.

A long time ago we theatergoers got used to omniscient narrators who have the ability to flit about seeing and knowing everything, even the secret thoughts inside people's heads, given the power of novelists to create characters straight from their own imaginations. 

We're told this "choice of voice" is a matter of tense and grammar, versus an author assuming superpowers to know in ways mere mortals don't.  Again, we're complicit in wanting this omniscience and will trust our authors and directors to conjure its facsimile.

Fiction denies the camera.  On the other hand, to acknowledge both an audience and a camera is not to escape the vortex of fiction and, in fact, escaping said vortex may not be the film maker's intent. Film and theater are art forms and fiction has always been fair game, ditto stage magic.  Newsreels came later.

I have no quarrel with fiction, nor have most moviegoers as a clientele, those who are sticklers for strictly the documentary genre being a relatively small minority overall.

However, speaking of documentaries, many of those deny the camera too:  there is no film team, this is not a film, is more the attitude.   Perhaps we have an omniscient narrator, that tells us what we need to know. 

Applying my criterion, I'd say such films tilt towards being fictional.  Non-fictional films include the process of making the film somehow and acknowledge the reality of an observer making a difference in some way, if only in choice of scenes.  An observer is also an editor.

Film removes two freedoms the novel reader takes pretty much for granted:  the freedom to "make the movie" in one's own mind, to imagine the action, and to create a point of view from which that action is perceived.

The theater substitutes an imagined scene for a real one, acted out with scenery, and now the points of view are limited to those within the theater. Some are in the balcony or in boxes, whereas some sit below in the orchestra section.  Buying a seat is tantamount to choosing a viewpoint, as is buying a pair of good binoculars (or opera glasses as the case may be).

The convention with film and TV is the viewpoints are chosen for us.  This becomes more clear when we consider the alternatives.  Some [immersive recording devices](http://mybizmo.blogspot.com/2008/06/immersion-experience.html) provide a complete sphere or almost a complete sphere of action which the viewer may then swivel within, in real time, looking in different directions from a center point, as if turning one's head in all directions. 

In ordinary movies, one has a choice of what part of the screen to gaze at, but even then, a director is directing attention, choosing an angle, and if engaged at all, we usually see what we're intended to see.  Providing TV viewers with a remote control and the ability to pause, go forward, go back, pick a scene, play slowly... these were new powers that early ticket-buying film viewers did not enjoy.

Now it's getting easier to quote video, to splice it in, grabbing from free and/or for-a-fee sources. Making home movies that were clearly amateur was a possibility.  Nowadays, more with less and ephemeralization have taken their course and the barriers to going pro are less physical than psychological.

Sometimes we can move between a fictional no-camera-here scenario and a more grounded one. For example, when newsworthy events occur, it becomes possible to watch the "same" event through multiple news shows.

The added realism may come less from the news shows themselves, and more from one's recognizing oneself as a chief editor, somewhere along the production pipeline. 

"This is how I put it all together" one says to oneself, acknowledging one's process and assuming responsibility for a perspective.  This can be value added work, sometimes called analysis, or perhaps synthesis.  Perspectives, as much as perceptions, may be dangerously out of whack and should be tested, reality checked and reviewed.  Keeping it fictive actually keeps us out of the danger zone in the sense that we don't care if it's "actually true" or not.

One may take that approach even when many of the news sources are doing their best to erase or deflect attention from any sense of a camera with a point of view, an innate bias.  That's fine. Semi-fictionalized versions may be the best versions available. 

There's no depending on any input stream to stay purely factual.  Always allow for spin rather than fight the mere fact that spin exists, then apply counter-spin if you think that's in order or a part of your work.