---
title: Mathy Memes
id: 8576720852871277213
author: Kirby Urner
published: 2015-12-01T11:44:00.000-08:00
updated: 2016-01-16T14:07:34.766-08:00
blog: control_room
tags: 
---

[ [a first draft](https://groups.google.com/d/msg/mathfuture/2mCCtmdePbA/BUjBkyTQBgAJ) published to MathFuture, a Google Group ]

My talks at PyCons 
(Python conventions) and OSCONs (Open Source conventions) going back 
show me mounting the stage to decry "calculus mountain", by which I 
meant the obstacle course and sometimes source of disappointment occasioned by the "forced march" through "delta calculus" if 
wanting to get into a four year college, and by extension into a STEM 
field (or "work for NASA" as some put it).

My contention, in those years, was those like me who'd made it over calculus mountain 
-- I got into honors calc at Princeton, skipping the regular, had 
Thurston the topologist for a prof; we used Spivak's, Calculus on 
Manifolds -- found on the other side some "cool pools" i.e. an oasis of 
other mathy topics that could have been just as well taught in high 
school, providing alternatives to those not turned on by calculus.

An example of such a "cool pool", no delta calc required, is Group 
Theory.  Permutations at play.  More generally, what we today call 
"discrete mathematics" was screamingly relevant, in terms of the doors 
it opens, compared with "integration by parts", or so I believed.  I 
found other voices sang with mine.  I was part of a choir.  I also 
joined forces with those wanting to teach "how to code" (computer 
program) for core credit.

Fast forward and I'm in Oregon, 
joining a small lobby group to say to the legislature:  "You know those 
three years of math you require for a high school diploma?  We want to 
bring in discrete math topics and open up more space in STEM than just 
pre-calculus / calculus, whaddya say?"  As far as I can tell, pretty 
much all the states said "[OK](https://edhesive.com/blog/2016/iowa-may-require-cs-to-graduate-by-2018)" in unison i.e. they had no concrete 
objections to math-credit computer science.  So ruled without objection,
 right?

When it comes to marketing the possibility in 
practice however, that's another matter and big publishing gets 
involved.  I like to float mnemonics, easy to use -- but we hope not 
misleading -- memes.  Calling the conventional pre-calc / calc track 
"delta calculus", as I do above, is not how most people write.  The 
letter "delta", though used in differential / integral calculus, has not
 been made to "brand" it in that way.  High school calculus, as 
typically taught, does not go by any Greek letter.

[My innovation, then](http://worldgame.blogspot.com/2014/09/lambda-versus-delta.html), was to cast "delta calc" versus "lambda calc" as two flavors of 
"calc" (computation), like chocolate and vanilla.  No one said a given 
student can't do "swirl" (both flavors mixed together).

Lets
 be clear:  lambda calc already exists, one might point to the Princeton
 Institute for Advanced Study, a couple generations back:  Alonso Church
 and company.  So where do we want to take it next?

Lets remember
 that so-called "delta calculus" was at one time esoteric and not 
introduced pre-college.  In formalizing the work of Newton and Leibniz, 
as filtered through generations of refinement, thank the French, we got 
it into the form of pre-college deliverables, a spiral, a ladder, 
featuring Riemann sums and Leibniz notation for derivatives, first, 
second, third and so on.  Different school systems have different 
histories.  Many narratives criss-cross (inter-weave).

In 
canning calculus ("canning" as in "canning tuna" not as in "firing from a
 job") for the pre-college crowd, we sliced out most of the history.  We
 take for granted that mathematics, being a "universal language" is 
somehow too eternal to be subjected to a merely tempo-real -- as in 
historical -- treatment.  That's considered aftermarket trade book 
reading.  Textbooks must peek at history only in sidebar, or in footnotes 
maybe.  

Whatever the rationale for so sanitizing the subject, we
 neglect a most important bridge to the humanities i.e. here is where 
C.P. Snow's chasm, betwixt the humanities and sciences begins to yawn.  
History provides at least a rope bridge across, whereas many find 
themselves trapped, on one side or the other (reading maths or reading 
history, but never the twain together thanks to illiteracy barriers).

Were
 we to restore more of the history, we would discover more of the all 
too human drama of contention.  But is debate a bad thing?  Isn't moving
 forward a matter of dialog, or "dialectic" as the educated say?  

Mathematics
 has not evolved quietly, without argument.  Newton and Leibniz argued 
with each other (a priority dispute) while Bishop Berkeley attacked the 
whole idea of infinitesimal quantities and proofs based on them (a 
conceptual integrity dispute).  Cantor and Kronecker took different 
sides in some arguments.  There's ferment, disagreement, or at least 
alternative ways to go.

But that's precisely what gets white washed in going over this material:  schools find it expedient to agree 
there's at least one subject on which everyone agrees.  Or, if they 
don't, at least none of the boiling-over arguments should touch the kids.  That math is contentious gets "dirty secret" or "in the closet" treatment.  
But Thomas Kuhn in his talk of "paradigms" at least made it OK / safe to
 question the caricature of a "steady advance" did he not?  So why be so
 timid?  Why all the shielding?

Anyway, in rolling up "lambda 
calculus" into a more popular form, like was done already with the 
Newton - Leibniz stuff, I've focused on "composition of functions" as 
the primitive notion, with the multiplication operator very soon 
introduced as a "composer operator", so that we further develop that 
sense of polymorphism around operators, the ground of Abstract Algebra.

[A permutation](http://worldgame.blogspot.com/2015/11/permutations.html), a mapping of objects to themselves in another or same 
order, is a primitive function, a set of ordered pairs.  It's 
one-to-one, bijective.  And permutations may be "chained" (composed).  
As a topic, they thicken the soup of whatever computer language, giving a
 gym to work out in.

"Why use the multiplication operator at 
all?"  That's where the "cool pool" of Group Theory comes in.  This is 
material we currently try to get into around Algebra 1 and 2, just a 
little, but we're in a hurry to dive into delta calc.

We have no time 
for passing functions as arguments to other functions, as we do in 
Python and other languages (that's a good introduction to delta calc 
too, through the gate of functions with function-arguments).

But now we
 do have that time, because we have a fork in the road and the freedom 
to follow the lambda calc road instead, or in addition, to the delta 
calc road.  The lambda calc road is certified legal and open to traffic,
 we just need more teachers to help out as guides.

I'm 
under no illusions that with the snap of some fingers, even more than 
just mine, these "reforms" might be injected in short order.  Rather I'm
 providing a road map for like-minded to reference, when explaining to 
the general public or intelligent layman what the strategy is.  "All the
 computer stuff we don't currently manage to squeeze in? -- we've got a 
way now, and I can explain it in terms of two Greek letters, lambda and 
delta".

I've "rehabilitated" obscure disciplines before, 
too early to assess with what success.  General Systems Theory (GST) is 
all over the place (somewhat like Tensegrity), as a management 
philosophy, as a kind of ecology, who knows?  It has a high caliber 
pedigree but where does it go from here?  

I noticed how 
Economists and Economics tend to have monopoly status when it comes to 
advising the financial markets regarding guns vs. butter, and suggested 
GST muscle in under the banner that "monopoly breeds inefficiency" owing
 to lack of serious competition.  GST was about giving Economics a run 
for its money.  Still is.  That's easy to understand, no?

Courses in 
GST could just as well provide rungs of that "climbing some business 
world ladder" as more science-oriented than Econ in some dimensions, 
including around issues of climate change we might hope.

Finally, another axis or spectrum I've contemplated, as have many, is what oft 
goes by "left brain" versus "right brain" as a dichotomy.  My track 
record is riddled with slides talking about "lexical versus graphical" 
by which I somewhat mean the same thing as the brain hemisphere people 
do.  We're talking about bridges again.

In STEM a goal is to have 
noodling-with-symbols (call it "algebra" or "being lexical") match up 
with visualizations and other experiential presentations or summaries.  
We want to understand what we're looking at when interpreting all that 
data.

Control panels, dashboards, instruments, sensors...  we 
have a kind of model, view, controller architecture to consider, where 
what we reason about and codify using semi-numerical algorithms is the 
model, the business logic, and what we view and measure is feedback 
regarding our direction, as a company or enterprise or whatever.

We 
hope for some kind of decision-making or steering capacity, where 
choosing a more promising direction, over a less promising one, remains a
 possibility.  We're hoping to be more like pilots, not just witnesses 
to the inevitable, spectator-fatalists with no active role.  "Activism" 
is not a negative, but informed and effective activism is better yet.  
"Passivism" is not an English word, but needs to be, as many are 
militantly passivist in their anti-activism.  I think "reactionary" is 
getting tired and needs a rest.

One of the best 
left-right i.e. lexical-graphical connectors I've found is using string 
substitution in lexical computer code to build a script that, when 
rendered, provides a ray tracing and / or perhaps a 3D printable 
object.  VRML and POV-Ray scene description language were often my two 
top choices, with similar choices in Elastic Interval Geometry land (a 
branch I was following).  

The 2D fractal, the Mandelbrot Set in 
particular, coupled with some historical timeline information, is a 
perfect topic, a sweet spot.  A strong lambda calculus course could set 
its sights in that direction:   doing the vector math lexically, with 
overloaded operators (like + and *), yet driving graphics on the 
screen.  Gerald de Jong's "creatures" provide a great example, of "math 
puppets" turning logic into animations.

Another 
approach to bridging model-lexical with viewable-graphical is to simply 
build up the skills to create a dynamic web page, where things happening
 graphically are driven by things happening lexically in the code.  In 
my Digital Mathematics outline, I cover that in "[Supermarket Math](http://wikieducator.org/Supermarket_Math)" which
 would cover "e-commerce" (but regular commerce as well, as brick and 
mortar stores use SQL just as much).  Mine is but one more sandcastle on
 this pretty big beach -- just take a few ideas, flatter me by copying.

The goal is to forge these left-right connections, even as we bridge the C.P. Snow chasm by remembering to share more history.